---
title: "카메라 좌표계시스템 정리 1편"
date: 2023-06-17 23:45:00 +0900
categories: 
    - CV
---

---

## Computer Vision 과 카메라 Coordinate Systems

우리가 카메라와 관련된 문제들을 정의하고 풀어내기 위해서는 카메라와 관계된 좌표계 시스템들을 이해하면 훨씬 쉽습니다.



![image-20230618160600285](C:\Users\user\OneDrive\바탕 화면\Mosquito0076.github.io\assets\images\image-20230618160600285.png)

```
•3D : World Coordinate System - 카메라가 바라본 3차원 세상이 기준으로 하는 월드 좌표계
•3D : Camera Coordinate System - 카메라를 기준으로 한 카메라 좌표계
•2D : Image Coordinate System - 카메라 내부의 이미지 센서에 대한 좌표계
•2D : Normalized lmage Coordinate System – 카메라 내부 파라미터의 영향을 제거한 정규 이미지 좌표계
```



먼저 3차원 월드 좌표계가 있습니다. 

카메라가 담는 세상이 기준으로 하는 3차원 좌표계입니다. 따로 정해져 있지 않기 때문에 이 좌표계는 우리가

풀려는 문제 상황에 맞게 임의로 정의 해줄 수 있습니다.



다음은 카메라를 기준으로 한 3차원 카메라 좌표계가 있습니다.

그리고 카메라 내부에 들어가면 2차원의 카메라 이미지 센서 좌표계가 있고, 

카메라의 내부 파라미터 영향을 제거한 정규 이미지 좌표계가 있습니다.



그림을 보면 월드 좌표계 상의 점 P가 있는데, 이는 extrinsic matrix를 통해 3차원 카메라 기준 좌표계로 표현될 수 있습니다.

그리고 이 점은 카메라 좌표계 의 원점을 기준으로 이미지 센서나 정규 이미지에 투영되게 됩니다.

이때는 intrinsic matrix가 이 관계를 표현해주는 것이죠



그럼 3차원 월드상의 좌표가 어떻게 카메라의 2차원 이미지 평면에 맺히는지 순서대로 살펴 봅시다.





### 1. 3D World Coordinate System -> 3D Camera Coordinate System

![image-20230618161111698](C:\Users\user\OneDrive\바탕 화면\Mosquito0076.github.io\assets\images\image-20230618161111698.png)

3차원 월드 좌표계상에서 표현된 카메라의 위치, 방향 정보를 알고 있다면 EXTRINSIC MATRIX를 구성하기에 충분합니다.

월드 좌표계 원점 기준으로  카메라의 원점이 위치한 좌표계 까지의 3축에 대한 평행이동 량을 알고 있으면 됩니다.

그리고 월드 좌표계의 3축이 그림과 같을때, 카메라가 바라보는 방향을 알 수 있다면 3축에 대한 회전으로 카메라의 방향을 표현할 수 있습니다.

따라서 카메라를 월드 좌표계상으로부터의 위치(3축에 대한 평행이동량)와 방향(3축에 대한 회전량)으로 표현으로 표현이 가능하다는 것입니다.

즉, **카메라 좌표계는 월드 좌표계 원점(0_X, 0_Y, 0_Z) 으로부터의 translation 과 rotation 으로 표현 가능** 합니다.





![image-20230618161428752](C:\Users\user\OneDrive\바탕 화면\Mosquito0076.github.io\assets\images\image-20230618161428752.png)





이제 정리를 한번 해봅시다.

- Translation :  월드 좌표계 원점으로부터 x축, y축, z축으로 특정 값 만큼 이동했을때 카메라 좌표계 원점이 되는 평행이동 행렬
- Rotation   :  월드 좌표계의 축을 카메라 좌표계의 축으로 맞추기 위해 필요한 3축에 대한 회전 행렬



![image-20230618161552038](C:\Users\user\OneDrive\바탕 화면\Mosquito0076.github.io\assets\images\image-20230618161552038.png)

위 식을 통해 이를 풀어내봅시다.

1번식을 보면 카메라 기준 좌표계로 표현된 점이 왼쪽이고 오른쪽에 월드 좌표계 기준으로 표현된 xyz가 있습니다.

오른쪽에 월드 좌표계 기준으로 표현된 점에 Rotation 매트릭스를 곱하고 translatio을 더하면 카메라 기준 좌표계로 표현됩니다.

Rotation의 경우 3축에 대한 회전을 반영하므로, 2번 식처럼 나타낼 수 있습니다.

**월드 좌표계 상의 점 P (X_w, Y_w, Z_w) 에 회전행렬 R 과 평행이동 벡터 행렬 T 를 적용하면,** 

**카메라 좌표계에서 바라본 점 P (X_C, Y_C, Z_C) 이 되는 것입니다.**





이제 식을 동차좌표계를 이용하여 간단하게 표현하겠습니다.

![image-20230618161605167](C:\Users\user\OneDrive\바탕 화면\Mosquito0076.github.io\assets\images\image-20230618161605167.png)



자 이제 3차원 월드 좌표계의 점이, 3차원 카메라 좌표계 기준으로 표현됨을 파악하였습니다.

이제부터는 이 점을 가지고 카메라 내부의 이미지 센서 어디에 투영되는지 파악하면 됩니다.

사실 투영변환 매트릭스의 핵심은 바로 이 3차원 좌표점이 카메라 내부 이미지 평면의 어디에 2차원으로 투영되는가에 대한 기하학적 관계라고 볼 수 있습니다.

이를 위해 intrinsic matrix가 필요한 것이죠 

다음장에서 어떻게 투영되는 것인지 살펴봅시다.





### 2. 3D Camera Coordinate System -> 2D lmage Coordinate System

카메라는 다양한 내부 파라미터를 가집니다 

- ex) 초점거리, 주점, 비대칭 계수, 렌즈 왜곡 계수(방사왜곡, 접선왜곡)

아래 그림은 카메라 내부 파라미터 중 초점거리( **f** )를 예시로 들었습니다.

- 초점거리는 이미지 센서(CMOS, CCD 등)와 렌즈중심 간의 거리
  (아래 그림에서 실제 카메라는 여러 개의 렌즈가 장착된 장치이나, 설명을 간단히 하기 위해 렌즈를 1개로 표현함)

![image-20230618162933230](C:\Users\user\OneDrive\바탕 화면\Mosquito0076.github.io\assets\images\image-20230618162933230.png)



위 그림을 봅시다. 카메라의 단편적인 모습인데 피사체에 반사된 빛을 점 P로부터의 초록색 선이라고 해보겠습니다.

이 빛은 렌즈의 중심으로 입사하게 되고 카메라 내부의 이미지 센서에 투영됩니다.

이때 이 투영될때 영향을 미치는 요소들을 카메라 내부 (intrinsic) 파라미터라고 하는데, 
정확하게는 초점거리, 주점, 비대칭 계수, 렌즈에 대한 왜곡 계수 등 가 있습니다.



흔히 초점거리라고 하면 카메라의 볼록렌즈의 초점을 생각할 수도 있는데, 이 카메라 모델에서는 렌즈중심과 이미지 센서와의 거리를 말합니다.

그림처럼 카메라 내부 이미지 센서와 렌즈 중심 사이 거리를 초점거리 f 라고 하는데, 픽셀 단위로 표현됩니다

이미지 좌표 단위인 픽셀은 이미지 센서의 cell에 대응되는 것이기 떄문에, 초점거리가 픽셀단위로 표현된다는 의미는, 

초점거리가 이미지 센서의 cell에 대한 상대적인 값으로 표현된다는 뜻입니다.

컴퓨터 비전에서 카메라 초점거리를 물리적 단위인 mm 나 츠 으로 표현하지 않고 굳이 픽셀 단위로 표현하는 이유는 이미지 좌표계의 단위인 픽셀과 동일하게 표현함으로써 기하학적 해석을 편하게 해주기 위함입니다.



주점(principal point) 는 카메라 렌즈의 중심에서 이미지 센서에 내린 수선의 발의 픽셀 좌표입니다.

우리가 흔히 말하는 영상의 중심점과는 다릅니다.

카메라 공정과정에서 오차로 인해 렌즈와 이미지 센서간 수평이 어긋나면 주점과 영상 중심점은 다른 값을 가지게 되는 것이죠

우리가 다루는 영상 기하학에선 이 단순한 이미지 중심점은 중요하지 않으며 주점이 중요합니다.

모든 기하학적 해석은 이 주점을 활용하여 다룹니다.

단, 우리 프로그램 상 구현된 렌즈는 이러한 공정과정에서의 오차가 없으므로, 픽셀 이미지 의 중심을 주점과 같다고 해도 무방합니다.



비대칭 계수는 이미지 센서의 cell 배열이 기울어진 정도를 나타내는데 이제는 더 이상 나타나지 않는 공정과정에서의 에러라고 봐도 됩니다.



이중에 초점거리를 예시로 한번 다뤄봅시다. 왜 이런 요소들이 카메라에 상이 맺히는 관계에 영향을 줄까요?

그림을 봅시다. 추점거리가 다른 카메라 2대가 있습니다.

왼쪽의 경우 초점거리가 짧은 카메라이고 오른쪽은 그 반대의 경우입니다.

초점거리가 짧을수록 주점에서 더 가갑게 상이 투영됩니다. 길수록 주점에 더 멀게 투영됩니다.

실제로도 intrinsic 매트릭스를 보면 이 관계가 반영되있습니다. 즉, 정비례하도록 좌표점이 투영됩니다.
